{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import pprint\n",
    "import pymorphy2\n",
    "import datetime\n",
    "import psycopg2\n",
    "\n",
    "from nltk import FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearDB(fileID):\n",
    "    sql = \"DELETE FROM terms WHERE doc_code = %s\"\n",
    "    conn = psycopg2.connect(host=\"localhost\", database=\"terms\", user=\"postgres\", password=\"admin\")\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql, (fileID, ))\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(fileName):\n",
    "    data = []\n",
    "    stop_words = getStopWords('russian')\n",
    "    file = codecs.open(dirName + \"/\" + fileName, mode=\"r\", encoding=\"utf-8-sig\")\n",
    "    for line in file:       # читаем по строкам\n",
    "        # убираем знаки пунктуации\n",
    "        line = line.replace('(', ' ')\n",
    "        line = line.replace(')', ' ')\n",
    "        line = line.replace('.', ' ')\n",
    "        line = line.replace(',', ' ')\n",
    "        line = line.replace(':', ' ')\n",
    "        line = line.replace(';', ' ')\n",
    "        line = line.replace('№', ' ')\n",
    "        line = line.replace('#', ' ')\n",
    "        line = line.replace('\"', ' ')\n",
    "        line = line.replace('«', ' ')\n",
    "        line = line.replace('«', ' ')\n",
    "        line = line.replace('—', '-')\n",
    "        line = line.replace('–', '-')\n",
    "\n",
    "        # переводим все слова в нижний регистр\n",
    "        line = line.lower()\n",
    "        r = line.split()    # массив слов\n",
    "\n",
    "        # убираем стоп-слова\n",
    "        r = [i for i in r if (i not in stop_words)]\n",
    "\n",
    "        if len(r) > 0:\n",
    "            data.append(r)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStopWords(lang):\n",
    "    stop_words = stopwords.words(lang)\n",
    "    stop_words.extend(\n",
    "    ['всё', 'все',\n",
    "    'своей', 'своя', 'свою', 'своими',\n",
    "    'которая', 'который', 'которые', 'которое',\n",
    "    'иной', 'иная', 'иное', 'иные', 'иных', 'иными',\n",
    "    'другой', 'другая', 'другие', 'другое',\n",
    "    'соответствующий',\n",
    "    'что',\n",
    "    'это', 'этот', 'эти', 'этих', 'эта', 'этому',\n",
    "    'тот', 'те', 'тех', 'та',\n",
    "    'так', 'также',\n",
    "    'вот',\n",
    "    'быть',\n",
    "    'как',\n",
    "    'в',\n",
    "    '—', '–', '-',\n",
    "    'к',\n",
    "    'на',\n",
    "    '...',\n",
    "    'декабрь',    'январь',    'февраль',\n",
    "    'март',    'апрель',    'май',\n",
    "    'июнь',    'июль',    'август',\n",
    "    'сентябрь',    'октябрь',    'ноябрь',\n",
    "    'казахстан', 'республика',\n",
    "    '1', '2', '3', '4', '5', '6', '7', '8', '9', '0'])\n",
    "    \n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareFreqDistNoun(data):\n",
    "    fdist = FreqDist()\n",
    "\n",
    "    # считаем частоту существительных (переводим в единственное число и именительный падеж)\n",
    "    # Термин состоит из СУЩЕСТВИТЕЛЬНОГО в ИМЕНИТЕЛЬНОМ падеже\n",
    "    for line in data:\n",
    "        for w in line:\n",
    "            if (w[0:1] == '-'):\n",
    "                w = w[1:]\n",
    "\n",
    "            try:\n",
    "                m = morph.parse(w)[0]\n",
    "                if m.tag.POS == 'NOUN':\n",
    "                    snw = morph.parse(w)[0].inflect({'sing', 'nomn'})\n",
    "                    fdist[snw.word] += 1\n",
    "            except:\n",
    "##                print(\"Error:\")\n",
    "##                pprint.pprint(w)\n",
    "                pass\n",
    "    return fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeFreqDist2DB(freq, fileID):\n",
    "    sql = \"INSERT INTO terms (term, doc_code, cnt) VALUES (%s, %s, %s)\"\n",
    "    conn = psycopg2.connect(host=\"localhost\",database=\"terms\", user=\"postgres\", password=\"admin\")\n",
    "\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    for w in freq.most_common():\n",
    "        cur.execute(\"INSERT INTO terms (term, doc_code, cnt) VALUES (%s, %s, %s)\", (\"qwerty\", fileID.upper(), \"333\"))\n",
    "        #cur.execute(sql, (w[0], fileID.upper(), w[1]))\n",
    "        conn.commit()\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k030000442_\n",
      "k030000481_\n",
      "k070000212_\n",
      "k090000193_\n",
      "k1400000235\n",
      "k1500000375\n",
      "k1500000414\n",
      "k1700000125\n",
      "k940001000_\n",
      "k990000409_\n",
      "p1000001202\n",
      "z000000053_\n",
      "z010000242_\n",
      "z010000245_\n",
      "z020000332_\n",
      "z030000476_\n",
      "z040000567_\n",
      "z040000588_\n",
      "z040000603_\n",
      "z060000175_\n",
      "z090000165_\n",
      "z1100000469\n",
      "z1200000020\n",
      "z1200000532\n",
      "z1200000541\n",
      "z1400000188\n",
      "z1400000194\n",
      "z1400000202\n",
      "z1500000434\n",
      "z1600000480\n",
      "z1600000486\n",
      "z1800000183\n",
      "z920002900_\n",
      "z940007000_\n",
      "z960000006_\n"
     ]
    }
   ],
   "source": [
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "dirName = \"corpus\"\n",
    "listdir = os.listdir(dirName)\n",
    "\n",
    "for fileName in listdir:           # каждый файл в директории\n",
    "    fileID = fileName.split('.')[0]\n",
    "    print(fileID)\n",
    "    clearDB(fileID)\n",
    "    data = prepareData(fileName)\n",
    "    \n",
    "    dict1w = FreqDist()\n",
    "    dict1w.update(prepareFreqDistNoun(data))\n",
    "    writeFreqDist2DB(dict1w, fileID)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
