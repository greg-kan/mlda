{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is supporting material for the book\n",
    "# Building Machine Learning Systems with Python\n",
    "# by Willi Richert, Luis Pedro Coelho and Matthieu Brucher\n",
    "# published by PACKT Publishing\n",
    "#\n",
    "# It is made available under the MIT License\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the magic command `%matplotlib` to see the plots inline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston dataset\n",
    "\n",
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first regression attempt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=3.561.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0af9a25492a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mxmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m ax.plot([xmin, xmax],\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[1;33m[\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxmin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         '-', lw=2, color=\"#f9a602\")\n\u001b[0;32m     22\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \"\"\"\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coef_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m    198\u001b[0m                                dense_output=True) + self.intercept_\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    543\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    546\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=3.561.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression(fit_intercept=True)\n",
    "\n",
    "# Index number five in the number of rooms\n",
    "x = boston.data[:, 5]\n",
    "y = boston.target\n",
    "\n",
    "# lr.fit takes a two-dimensional array as input. We use np.atleast_2d\n",
    "# to convert from one to two dimensional, then transpose to make sure that the\n",
    "# format matches:\n",
    "x = np.transpose(np.atleast_2d(x))\n",
    "lr.fit(x, y)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_xlabel(\"Average number of rooms (RM)\")\n",
    "ax.set_ylabel(\"House Price\")\n",
    "xmin = x.min()\n",
    "xmax = x.max()\n",
    "ax.plot([xmin, xmax],\n",
    "        [lr.predict(xmin), lr.predict(xmax)],\n",
    "        '-', lw=2, color=\"#f9a602\")\n",
    "ax.scatter(x, y, s=2)\n",
    "fig.savefig('Regression_Fig_01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y, lr.predict(x))\n",
    "print(\"Mean squared error (on training data): {:.3}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mse)\n",
    "print('RMSE (on training data): {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y, lr.predict(x))\n",
    "print(\"R2 (on training data): {:.2}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat, but using all the input variables now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = boston.data\n",
    "\n",
    "lr.fit(x,y)\n",
    "\n",
    "mse = mean_squared_error(y, lr.predict(x))\n",
    "print(\"Mean squared error (on training data): {:.3}\".format(mse))\n",
    "rmse = np.sqrt(mse)\n",
    "print('RMSE (on training data): {}'.format(rmse))\n",
    "r2 = r2_score(y, lr.predict(x))\n",
    "print(\"R2 (on training data): {:.2}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how well we do, we plot _prediction vs. gold reality_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.set_xlabel('Predicted price')\n",
    "ax.set_ylabel('Actual price')\n",
    "ax.plot([y.min(), y.max()], [y.min(), y.max()], ':', lw=2, color=\"#f9a602\")\n",
    "ax.scatter(lr.predict(x), y, s=2)\n",
    "fig.savefig(\"Regression_FIG_02.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use **cross-validation** for evaluating the regression quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "kf = KFold(n_splits=5)\n",
    "p = cross_val_predict(lr, x, y, cv=kf)\n",
    "rmse_cv = np.sqrt(mean_squared_error(p, y))\n",
    "print('RMSE on 5-fold CV: {:.2}'.format(rmse_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compare a few different regression models on _both training data and using cross-validation_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, ElasticNet, Lasso, Ridge                              \n",
    "\n",
    "for name, met in [\n",
    "        ('linear regression', LinearRegression()),\n",
    "        ('elastic-net(.5)', ElasticNet(alpha=0.5)),\n",
    "        ('lasso(.5)', Lasso(alpha=0.5)),\n",
    "        ('ridge(.5)', Ridge(alpha=0.5)),\n",
    "]:\n",
    "    # Fit on the whole data:\n",
    "    met.fit(x, y)\n",
    "\n",
    "    # Predict on the whole data:\n",
    "    p = met.predict(x)\n",
    "    r2_train = r2_score(y, p)\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "    p = np.zeros_like(y)\n",
    "    for train, test in kf.split(x):\n",
    "        met.fit(x[train], y[train])\n",
    "        p[test] = met.predict(x[test])\n",
    "\n",
    "        r2_cv = r2_score(y, p)\n",
    "    print('Method: {}'.format(name))\n",
    "    print('R2 on training: {:.2}'.format(r2_train))\n",
    "    print('R2 on 5-fold CV: {:.2}'.format(r2_cv))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "las = Lasso(normalize=True)                            \n",
    "alphas = np.logspace(-5, 2, 1000)                   \n",
    "alphas, coefs, _= las.path(x, y, alphas=alphas)     \n",
    "\n",
    "fig,ax = plt.subplots()                             \n",
    "ax.plot(alphas, coefs.T)                            \n",
    "ax.set_xscale('log')                                \n",
    "ax.set_xlim(alphas.max(), alphas.min())             \n",
    "\n",
    "\n",
    "plt.title('Lasso coefficient path as a function of alpha')                                           \n",
    "ax.set_xlabel('Alpha')                              \n",
    "ax.set_ylabel('Coefficient weight')                 \n",
    "fig.savefig('REGRESSION_FIG_03.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and do the same with Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size, epochs\n",
    "batch_size = 100\n",
    "n_epochs = 50000\n",
    "steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the scaffolding\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = boston.data[:,5][:,None]\n",
    "y = np.reshape(boston.target, (-1, 1))\n",
    "\n",
    "nb_features = x.shape[1]\n",
    "\n",
    "X = tf.placeholder(shape=[None, nb_features], dtype=tf.float32, name=\"X\")\n",
    "Y = tf.placeholder(shape=[None, 1], dtype=tf.float32, name=\"y\")\n",
    "\n",
    "A = tf.Variable(tf.random_normal(shape=[nb_features, 1]), name=\"A\")\n",
    "b = tf.Variable(tf.random_normal(shape=[1,1]), name=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the graph\n",
    "model_output = tf.matmul(X, A) + b\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(Y - model_output))\n",
    "\n",
    "# Uncomment to get Ridge or Lasso\n",
    "\"\"\"\n",
    "beta = 0.005\n",
    "regularizer = tf.nn.l2_loss(A)\n",
    "loss = loss + beta * regularizer\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "beta = 0.5\n",
    "regularizer = tf.reduce_mean(tf.abs(A))\n",
    "loss = loss + beta * regularizer\n",
    "\"\"\"\n",
    "\n",
    "grad_speed = 1e-3\n",
    "my_opt = tf.train.GradientDescentOptimizer(grad_speed)\n",
    "train_step = my_opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optimization\n",
    "loss_vec = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(n_epochs):\n",
    "        permut = np.random.permutation(len(x))\n",
    "        for j in range(0, len(x), batch_size):\n",
    "            batch = permut[j:j+batch_size]\n",
    "            Xs = x[batch]\n",
    "            Ys = y[batch]\n",
    "\n",
    "            sess.run(train_step, feed_dict={X: Xs, Y: Ys})\n",
    "            temp_loss = sess.run(loss, feed_dict={X: Xs, Y: Ys})\n",
    "        \n",
    "        if epoch % steps == steps - 1:\n",
    "            temp_loss = sess.run(loss, feed_dict={X: x, Y: y})\n",
    "            loss_vec.append(temp_loss)\n",
    "\n",
    "            (A_, b_) = sess.run([A, b])\n",
    "            print('Epoch #%i  A = %s b = %s' % (epoch, np.transpose(A_), b_))\n",
    "            print('Loss = %.8f' % temp_loss)\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "    [slope, y_intercept] = sess.run([A, b])\n",
    "    prediction = sess.run(model_output, feed_dict={X: x})\n",
    "    mse = mean_squared_error(y, prediction)\n",
    "    print(\"Mean squared error (on training data): {:.3}\".format(mse))\n",
    "    rmse = np.sqrt(mse)\n",
    "    print('RMSE (on training data): {}'.format(rmse))\n",
    "    r2 = r2_score(y, prediction)\n",
    "    print(\"R2 (on training data): {:.2}\".format(r2))\n",
    "\n",
    "best_fit = []\n",
    "for i in x:\n",
    "    best_fit.append(slope[0]*i+y_intercept[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1D best fit\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_xlabel(\"Average number of rooms (RM)\")\n",
    "ax.set_ylabel(\"House Price\")\n",
    "\n",
    "ax.scatter(x, y, s=2, label='Data Points')\n",
    "ax.plot(x, np.array(best_fit), '-', lw=2, color=\"#f9a602\", label='Best fit line')\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "fig.savefig('REGRESSION_FIG_06.png')\n",
    "\n",
    "# Plot loss over time\n",
    "plt.figure()\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_title('Loss per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "\n",
    "ax.plot(loss_vec, 'k-')\n",
    "\n",
    "fig.savefig('REGRESSION_FIG_07.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we move to use all the features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the scaffolding\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = boston.data\n",
    "y = np.reshape(boston.target, (-1, 1))\n",
    "\n",
    "nb_features = x.shape[1]\n",
    "\n",
    "X = tf.placeholder(shape=[None, nb_features], dtype=tf.float32, name=\"X\")\n",
    "Y = tf.placeholder(shape=[None, 1], dtype=tf.float32, name=\"y\")\n",
    "\n",
    "A = tf.Variable(tf.random_normal(shape=[nb_features, 1]), name=\"A\")\n",
    "b = tf.Variable(tf.random_normal(shape=[1,1]), name=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the graph\n",
    "model_output = tf.matmul(X, A) + b\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(Y - model_output))\n",
    "\n",
    "# Uncomment to get Ridge or Lasso\n",
    "\"\"\"\n",
    "beta = 0.005\n",
    "regularizer = tf.nn.l2_loss(A)\n",
    "loss = loss + beta * regularizer\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "beta = 0.5\n",
    "regularizer = tf.reduce_mean(tf.abs(A))\n",
    "loss = loss + beta * regularizer\n",
    "\"\"\"\n",
    "\n",
    "grad_speed = 5e-7\n",
    "my_opt = tf.train.GradientDescentOptimizer(grad_speed)\n",
    "train_step = my_opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optimization\n",
    "loss_vec = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(n_epochs):\n",
    "        permut = np.random.permutation(len(x))\n",
    "        for j in range(0, len(x), batch_size):\n",
    "            batch = permut[j:j+batch_size]\n",
    "            Xs = x[batch]\n",
    "            Ys = y[batch]\n",
    "\n",
    "            sess.run(train_step, feed_dict={X: Xs, Y: Ys})\n",
    "            temp_loss = sess.run(loss, feed_dict={X: Xs, Y: Ys})\n",
    "        \n",
    "        if epoch % steps == steps - 1:\n",
    "            temp_loss = sess.run(loss, feed_dict={X: x, Y: y})\n",
    "            loss_vec.append(temp_loss)\n",
    "\n",
    "            (A_, b_) = sess.run([A, b])\n",
    "            print('Epoch #%i  A = %s b = %s' % (epoch, np.transpose(A_), b_))\n",
    "            print('Loss = %.8f' % temp_loss)\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "    [slope, y_intercept] = sess.run([A, b])\n",
    "    prediction = sess.run(model_output, feed_dict={X: x})\n",
    "    mse = mean_squared_error(y, prediction)\n",
    "    print(\"Mean squared error (on training data): {:.3}\".format(mse))\n",
    "    rmse = np.sqrt(mse)\n",
    "    print('RMSE (on training data): {}'.format(rmse))\n",
    "    r2 = r2_score(y, prediction)\n",
    "    print(\"R2 (on training data): {:.2}\".format(r2))\n",
    "\n",
    "best_fit = []\n",
    "for i in x:\n",
    "    best_fit.append(slope[0]*i+y_intercept[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss over time\n",
    "plt.figure()\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_title('Loss per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "\n",
    "ax.plot(loss_vec, 'k-')\n",
    "\n",
    "fig.savefig('REGRESSION_FIG_08.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## E2006 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "data, target = load_svmlight_file('data/E2006.train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute error on training data to demonstrate that we can obtain near perfect scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(data, target)\n",
    "pred = lr.predict(data) \n",
    "\n",
    "print('RMSE on training, {:.2}'.format(np.sqrt(mean_squared_error(target, pred))))\n",
    "print('R2 on training, {:.2}'.format(r2_score(target, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we do not do so well on cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "pred = cross_val_predict(lr, data, target, cv=kf)\n",
    "\n",
    "print('RMSE on testing (5 fold), {:.2}'.format(np.sqrt(mean_squared_error(target, pred))))\n",
    "print('R2 on testing (5 fold), {:.2}'.format(r2_score(target, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we try _an Elastic net_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the lines below if you want to switch method:                                                     \n",
    "met = ElasticNet(alpha=0.1)\n",
    "met.fit(data, target)\n",
    "pred = met.predict(data)\n",
    "\n",
    "print('[EN 0.1] RMSE on training: {:.2}'.format(np.sqrt(mean_squared_error(target, pred))))\n",
    "print('[EN 0.1] R2 on training: {:.2}'.format(r2_score(target, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a perfect prediction on the training data anymore, but let us check the value on cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cross_val_predict(met, data, target, cv=kf)\n",
    "\n",
    "print('[EN 0.1] RMSE on testing (5 fold): {:.2}'.format(np.sqrt(mean_squared_error(target, pred))))\n",
    "print('[EN 0.1] R2 on testing (5 fold): {:.2}'.format(r2_score(target, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use `ElasticNetCV` to set parameters automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "# Construct an ElasticNetCV object (use all available CPUs)\n",
    "met = ElasticNetCV(n_jobs=-1)\n",
    "\n",
    "met.fit(data, target)\n",
    "pred = met.predict(data)\n",
    "print('[EN CV] RMSE on training, {:.2}'.format(np.sqrt(mean_squared_error(target, pred))))\n",
    "print('[EN CV] R2 on training, {:.2}'.format(r2_score(target, pred)))\n",
    "\n",
    "pred = cross_val_predict(met, data, target, cv=kf)\n",
    "print('[EN CV] RMSE on testing (5 fold), {:.2}'.format(np.sqrt(mean_squared_error(target, pred))))\n",
    "print('[EN CV] R2 on testing (5 fold), {:.2}'.format(r2_score(target, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a a pretty good general-purpose regression object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Construct an ElasticNetCV object (use all available CPUs)\n",
    "met = ElasticNetCV(n_jobs=-1, l1_ratio=[.01, .05, .25, .5, .75, .95, .99])\n",
    "\n",
    "pred = cross_val_predict(met, data, target, cv=kf)\n",
    "\n",
    "print('[EN CV l1_ratio] RMSE on testing(5 fold), {:.2}'.format(np.sqrt(mean_squared_error(target, pred))))\n",
    "print('[EN CV l1_ratio] R2 on testing (5 fold), {:.2}'.format(r2_score(target, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the final result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(target, pred, c='k', s=1)\n",
    "ax.plot([-5,-1], [-5,-1], 'r-', lw=2)\n",
    "ax.set_xlabel('Actual value')\n",
    "ax.set_ylabel('Predicted value')\n",
    "fig.savefig('REGRESSION_FIG_05.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
