{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3 as sq\n",
    "import re\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_cleaner(text):\n",
    "        \n",
    "    text = re.sub( r'ЖАЛОБА: на ', '', text) # замена слов 'ЖАЛОБА: на '\n",
    "    text = re.sub( r'ЖАЛОБА: ', '', text) # замена слов 'ЖАЛОБА: на '\n",
    "    text = re.sub( r'Жалоба на ', '', text) # замена слов 'ЖАЛОБА: на '\n",
    "    text = re.sub( r'Жалобы на ', '', text) # замена слов 'ЖАЛОБА: на '\n",
    "    \n",
    "    #stw = ['ЖАЛОБА: ', 'ЖАЛОБА: на', 'Жалоба на', 'Жалобы на']\n",
    "    #remove = r'('+'|'.join(stw)+')'\n",
    "    ##remove = r'\\b('+'|'.join(stw)+')\\\\b'\n",
    "    #text = re.sub(remove, '', text)    \n",
    "\n",
    "    text = str.strip(text.lower())\n",
    "    return  text\n",
    "\n",
    "def text_cleaner(text):\n",
    "    text = text.lower() # приведение в lowercase,\n",
    "    \n",
    "    text = re.sub( r'https?://[\\S]+', ' url ', text) # замена интернет ссылок\n",
    "    text = re.sub( r'[\\w\\./]+\\.[a-z]+', ' url ', text) \n",
    " \n",
    "    # text = re.sub( r'\\d+[-/\\.]\\d+[-/\\.]\\d+', ' date ', text) # замена даты и времени\n",
    "    # text = re.sub( r'\\d+ ?гг?', ' date ', text) \n",
    "    # text = re.sub( r'\\d+:\\d+(:\\d+)?', ' time ', text) \n",
    "\n",
    "    # text = re.sub( r'@\\w+', ' tname ', text ) # замена имён twiter\n",
    "    # text = re.sub( r'#\\w+', ' htag ', text ) # замена хештегов\n",
    "\n",
    "    text = re.sub( r'<[^>]*>', ' ', text) # удаление html тагов\n",
    "    text = re.sub( r'[\\W]+', ' ', text ) # удаление лишних символов\n",
    "\n",
    "    stemmer = SnowballStemmer(\"russian\")\n",
    "    singles = [stemmer.stem(word) for word in text.split()]\n",
    "    text = ' '.join(singles)\n",
    "\n",
    "    # stw = ['в', 'по', 'на', 'из', 'и', 'или', 'не', 'но', 'за', 'над', 'под', 'то',\n",
    "    #        'a', 'at', 'on', 'of', 'and', 'or', 'in', 'for', 'at' ]\n",
    "    # remove = r'\\b('+'|'.join(stw)+')\\b'\n",
    "    # text = re.sub(remove,' ', text)\n",
    "    \n",
    "    # text = re.sub( r'\\b\\w\\b', ' ', text ) # удаление отдельно стоящих букв\n",
    "\n",
    "    text = re.sub( r'\\b\\d+\\b', ' digit ', text ) # замена цифр \n",
    "\n",
    "    return  text\n",
    "\n",
    "def train_test_split( data, validation_split = 0.2):\n",
    "    dict_data = data.to_dict('list')\n",
    "    sz = len(dict_data['TOPIC'])\n",
    "    indices = np.arange(sz)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    X = [ dict_data['DESCRIPTION'][i] for i in indices ]\n",
    "    Y = [ dict_data['TOPIC'][i] for i in indices ]\n",
    "    nb_validation_samples = int( validation_split * sz )\n",
    "\n",
    "    return { \n",
    "        'train': { 'x': X[:-nb_validation_samples], 'y': Y[:-nb_validation_samples]  },\n",
    "        'test': { 'x': X[-nb_validation_samples:], 'y': Y[-nb_validation_samples:]  }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22840, 21)\n"
     ]
    }
   ],
   "source": [
    "#Loading data\n",
    "raw_data = pd.read_csv('complaints.csv', header = 0, sep = ';')\n",
    "#raw_data.info()\n",
    "#raw_data.head()\n",
    "print(raw_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22805, 2)\n",
      "(19415, 2)\n",
      "\tколичество исходных категорий: 101\n",
      "{'обслуживание - кредиты', 'обслуживание - депозиты', 'обслуживание - терминалы', 'обслуживание - не рассказали', 'услугу \"хранитель\" - не рассказали', 'обслуживание - карта не закрылась', 'го/филиал/отделения/микроофисы/тт - некомфортное помещение', 'корреспонденцию банка - cмс по предложениям xsell', 'услугу \"хранитель\" - не возвращена сумма продукта', 'обслуживание - комиссии/тарифы банка', 'услугу \"защита семьи\"  - навязали', 'го/филиал/отделения/микроофисы/тт - неудобное месторасположение', 'корреспонденцию банка - прочее', 'услугу \"защита семьи\"  - некорректно проинформировали', 'услугу \"хранитель\" - фронт', 'обслуживание - не возвращена сумма продукта', 'корреспонденцию банка - кредиты', 'карточные продукты - na_u_topic', 'обслуживание - экстра лимит', 'услугу \"хранитель\" - na_u_topic', 'го/филиал/отделения/микроофисы/тт - корреспонденция (письма)', 'не согласие с условиями договора, %%, задолженностью, штрафами, тарифами и комиссиями - депозиты', 'обслуживание - корреспонденция (письма)', 'не согласие с условиями договора, %%, задолженностью, штрафами, тарифами и комиссиями - карты', 'обслуживание - обслуживание в отделениях', 'корреспонденцию банка - зеро промо', 'обслуживание - обслуживание в торговых точках', 'обслуживание - звонки/смс: другое', 'не согласие с условиями договора, %%, задолженностью, штрафами, тарифами и комиссиями - не работает; открылось позже', 'обслуживание в терминалах - поиск платежа', 'корреспонденцию банка - звонки/смс: другое', 'обслуживание - не выдан продукт', 'корреспонденцию банка - обслуживание в отделениях', 'го/филиал/отделения/микроофисы/тт - мало отделений', 'не согласие с условиями договора, %%, задолженностью, штрафами, тарифами и комиссиями - страховка', 'обслуживание - заявление: акции_платеж в подарок', 'го/филиал/отделения/микроофисы/тт - не обслуживают в обеденное время', 'не согласие с условиями договора, %%, задолженностью, штрафами, тарифами и комиссиями - кредиты', 'услугу \"страховку\" - na_u_topic', 'услугу \"хранитель\" - некорректно проинформировали', 'обслуживание в терминалах - корректировка платежа', 'обслуживание в терминалах - na_u_topic', 'услугу \"страховку\" - не рассказали', 'обслуживание - продукт', 'карточные продукты - зеро промо', 'не согласие с условиями договора, %%, задолженностью, штрафами, тарифами и комиссиями - выдача кредита', 'корреспонденцию банка - звонки по предложениям xsell', 'обслуживание - мало отделений', 'обслуживание - причина отказа', 'обслуживание в терминалах - некорректности платежа (не выдал чек, поступила неполная сумма, зажевал/выплюнул купюру)', 'го/филиал/отделения/микроофисы/тт - обслуживание в отделениях', 'корреспонденцию банка - смс с ошибочными данными', 'обслуживание - не работает; открылось позже', 'карточные продукты - walkin', 'обслуживание - na_u_topic', 'обслуживание - xsell', 'обслуживание - карты', 'обслуживание - звонки/смс по текущим кредитам и депозитам', 'не согласие с условиями договора, %%, задолженностью, штрафами, тарифами и комиссиями - na_u_topic', 'услугу \"страховку\" - страховка', 'услугу \"страховку\" - навязали', 'обслуживание - некорректно проинформировали', 'обслуживание - хранитель', 'обслуживание - обслуживание call-center', 'корреспонденцию банка - корреспонденция (письма)', 'услугу \"страховку\" - некорректно проинформировали', 'го/филиал/отделения/микроофисы/тт - не работает; открылось позже', 'корреспонденцию банка - обслуживание', 'корреспонденцию банка - na_u_topic', 'го/филиал/отделения/микроофисы/тт - закрылось раньше', 'услугу \"защита семьи\"  - na_u_topic', 'обслуживание - обслуживание в казпочте', 'го/филиал/отделения/микроофисы/тт - не работает касса', 'обслуживание - обслуживание в мо', 'обслуживание - обслуживание', 'обслуживание - навязали', 'корреспонденцию банка - кредитные', 'обслуживание - звонки/смс по пре-коллекшн', 'услугу \"хранитель\" - продукт', 'услугу \"хранитель\" - навязали', 'услугу \"хранитель\" - не выдан продукт', 'го/филиал/отделения/микроофисы/тт - терминалы', 'обслуживание - звонки по предложениям xsell', 'обслуживание в терминалах - фронт', 'карточные продукты - прочее', 'карточные продукты - xsell', 'не согласие с условиями договора, %%, задолженностью, штрафами, тарифами и комиссиями - прочее', 'карточные продукты - карты', 'го/филиал/отделения/микроофисы/тт - na_u_topic', 'карточные продукты - экстра лимит', 'услугу \"защита семьи\"  - не рассказали', 'обслуживание - зеро промо', 'не согласие с условиями договора, %%, задолженностью, штрафами, тарифами и комиссиями - хранитель', 'корреспонденцию банка - звонки/смс по текущим кредитам и депозитам', 'обслуживание - выдача кредита', 'корреспонденцию банка - обслуживание call-center', 'обслуживание - защита семьи', 'не согласие с условиями договора, %%, задолженностью, штрафами, тарифами и комиссиями - комиссии/тарифы банка', 'корреспонденцию банка - звонки/смс по пре-коллекшн', 'обслуживание - работников взыскания', 'обслуживание - прочее'}\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing\n",
    "raw_data = raw_data.dropna(subset=['TOPIC']) \n",
    "valuable_columns = [\"TOPIC\", \"DESCRIPTION\"]\n",
    "raw_data[\"TOPIC\"] = raw_data[\"TOPIC\"] + \" - \" + raw_data[\"UNDER_TOPIC\"].fillna('NA_U_TOPIC')\n",
    "\n",
    "raw_data = raw_data[valuable_columns]\n",
    "\n",
    "print(raw_data.shape)\n",
    "\n",
    "raw_data = raw_data[(raw_data.TOPIC.str.contains(\"ЖАЛОБА: \") |\n",
    "                     raw_data.TOPIC.str.contains(\"Жалоба на \") |\n",
    "                     raw_data.TOPIC.str.contains(\"Жалобы на \"))] #, na=False\n",
    "\n",
    "print(raw_data.shape)\n",
    "\n",
    "raw_data[\"TOPIC\"] = [ label_cleaner(t) for t in raw_data[\"TOPIC\"]]\n",
    "\n",
    "print(\"\\tколичество исходных категорий:\", len(set(raw_data[\"TOPIC\"])))\n",
    "print(set(raw_data[\"TOPIC\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tразмер тестовой выборки: 3883\n",
      "\tразмер тренировочной выборки: 15532\n"
     ]
    }
   ],
   "source": [
    "#Splitting to train and test\n",
    "D = train_test_split(raw_data, 0.2)\n",
    "\n",
    "print(\"\\tразмер тестовой выборки:\", len(D['test'] ['y']))\n",
    "print(\"\\tразмер тренировочной выборки:\", len(D['train'] ['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] обучение классификатора...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] обучение завершено!\n"
     ]
    }
   ],
   "source": [
    "#Learnming a classificator\n",
    "print(\"[i] обучение классификатора...\")\n",
    "\n",
    "    # text_clf = Pipeline([\n",
    "    #                ('hashvect', HashingVectorizer() ),\n",
    "    #                ('tfidf', TfidfTransformer(use_idf=False )),\n",
    "    #                ('clf', SGDClassifier(loss='hinge')),\n",
    "    #                ])\n",
    "    #\n",
    "    # text_clf = Pipeline([\n",
    "    #                ('covect', CountVectorizer() ),\n",
    "    #                ('tfidf', TfidfTransformer(preprocessor=text_cleaner,use_idf=False )),\n",
    "    #                ('clf', SGDClassifier(loss='hinge')),\n",
    "    #                ])\n",
    "\n",
    "\n",
    "text_clf = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer()),\n",
    "                ('clf', SGDClassifier(loss='hinge')),\n",
    "                ])\n",
    "\n",
    "text_clf.fit(D['train']['x'], D['train']['y'])\n",
    "\n",
    "print(\"[i] обучение завершено!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] тестируем...\n",
      "\taccuracy train:  0.8315735256245171\n",
      "\taccuracy test:  0.5207313932526397\n"
     ]
    }
   ],
   "source": [
    "#Testing and checking results\n",
    "print(\"[i] тестируем...\")\n",
    "\n",
    "predicted = text_clf.predict( D['train']['x'] )\n",
    "print(\"\\taccuracy train: \", accuracy_score(  D['train']['y'] , predicted) )\n",
    "    \n",
    "predicted = text_clf.predict( D['test']['x'] )\n",
    "print(\"\\taccuracy test: \", accuracy_score(  D['test']['y'] , predicted) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
